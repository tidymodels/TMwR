```{r workflow-setup, include = FALSE}
knitr::opts_chunk$set(fig.path = "figures/")
library(tidymodels)
library(kableExtra)

data(ames, package = "modeldata")

ames <- mutate(ames, Sale_Price = log10(Sale_Price))

set.seed(833961)
ames_split <- initial_split(ames, prob = 0.80, strata = Sale_Price)
ames_train <- training(ames_split)
ames_test  <-  testing(ames_split)
```

# A model workflow {#workflows}

In previous chapters, the `recipes` and `parsnip` packages have been discussed. They can be used to prepare the data for analysis and fitting the model. In this chapter, another object is described called a _model workflow_. The purpose of this object is to encapsulate the major pieces of the modeling _process_ (previously discussed in Section \@ref(model-phases)). As will be shown below, the workflow is important in two ways. First, the workflow encourages good methodology since it is a single point of entry to the estimation components of a data analysis. Second, it enables the user to better organize their projects. These two points are discussed in the following sections.  


## Where does the model begin and end? {#begin-model-end}

So far, "the model" has been defined as a structural equation that relates some predictors to one or more outcomes. Let's consider again linear regression as an example. The outcome data are denoted as $y_i$, where there are $i = 1 \ldots n$ samples in the training set. Suppose that there are $p$ predictors $x_{i1}, \ldots, x_{ip}$ that are used in the model. Linear regression produces a model equation of 

$$ \hat{y}_i = \hat{\beta}_0 + \hat{\beta}_1x_{i1} + \ldots + \hat{\beta}_px_{ip} $$

While this is a _linear_ model, it is only linear in the parameters. The predictors could be nonlinear terms (such as the $log(x_i)$). 

The conventional way of thinking is that the modeling _process_ only includes the model fit. For many data sets that are straight-forward in nature, this is the case. However, there are a variety of _choices_ and additional steps that often occur before the data are ready to be added to the model. Some examples:

* While our model has $p$ predictors, it is common to start with more than $p$ candidate predictors. Through exploratory data analysis or previous experience, some of the predictors may be excluded from the analysis. In other cases, some feature selection algorithm may have been used to make a data-driven choice for the minimum predictors set for the model. 
* There are times when the value of an important predictor is missing. Rather than eliminating this sample from the data set, the missing value could be _imputed_ using other values in the data. For example, if $x_1$ were missing but was correlated with predictors $x_2$ and $x_3$, an imputation method could estimate the missing $x_1$ observation from the values of $x_2$ and $x_3$. 
* As previously mentioned, it may be beneficial to transform the scale of a predictor. If there is **not** _a priori_ information on what the new scale should be, it might be estimated using a transformation technique. Here, the existing data would be used to statistically _estimate_ the proper scale that optimizes some criterion. Other transformations, such as the previously mentioned PCA, take groups of predictors and transform them into new features that are used as the predictors.

While the examples above are related to steps that occur before the model fit, there may also be operations that occur after the model is created. For example, when a classification model is created where the outcome is binary (e.g., `event` and `non-event`), it is customary to use a 50% probability cutoff to create a discrete class prediction (also known as a "hard prediction"). For example, a classification model might estimate that the probability of an event was 62%. Using the typical default, the hard prediction would be `event`. However, the model may need to be more focused on reducing false positive results (i.e., where true non-events are classified as events). One way to do this is to _raise_ the cutoff from 50% to some greater value. This increases the level of evidence required to call a new sample as an event. While this reduces the true positive rate (which is bad), it may have a more profound effect on reducing false positives. The choice of the cutoff value should be optimized using data. This is an example of a _post-processing_ step that has a significant effect on how well the model works even though it is not contained in the model fitting step. 

These examples have a common characteristic of requiring data for derivations that alter the raw data values or the predictions generated by the model. 

It is very important to focus on the broader _model fitting process_ instead of the specific model being used to estimate parameters. This would include any pre-processing steps, the model fit itself, as well as potential post-processing activities. Here, this will be referred to as the **model workflow** and would include any data-driven activities that are used to produce a final model equation. 

```{block, type = "rmdnote"}
In other programs, such as python or Spark, similar collections of steps are called  _pipelines_. In tidymodels, the term "pipeline" already connotes a sequence of operations chained together with a pipe operator (such as `%>%`). Rather than confusing terminology, the sequence of computational operations related to modeling will be called **workflows**. 
``` 

Binding together the analytical components of a data analysis is important for another reason. Future chapters will demonstrate how to accurately measure performance as well as how to optimize structural parameters (i.e. model tuning). To correctly quantify model performance on the training set, Chapter \@ref(resampling) advocates using _resampling_ methods. To do this properly, no data-driven parts of the analysis should be excluded from validation. To this end, the workflow should include all significant estimation steps.

To illustrate, consider PCA signal extraction. This was previously mentioned in Section \@ref(other-steps) as a way to replace the correlated predictors with new artificial features that are uncorrelated and capture most of the information in the original set. The new features would be used as the predictors and least square regression could be used to estimate the model parameters. 

There are two ways of thinking about the model workflow. The _incorrect_ method would be to think of the PCA pre-processing step as not being part of the modeling process: 

```{r workflow-bad, echo = FALSE, out.width = '80%', warning = FALSE}
if (knitr:::is_html_output()) {
  file.copy("premade/bad-workflow.svg", "_book/premade/bad-workflow.svg")
  knitr::include_graphics("premade/bad-workflow.svg")
} else {
  file.copy("premade/bad-workflow.pdf", "_book/premade/bad-workflow.pdf")
  knitr::include_graphics("premade/bad-workflow.pdf")
}
```

The fallacy here is that, although PCA does significant computations to produce the components, its operations has no uncertainty associated with it. In effect, the PCA components would be treated as _known_ and, if not included in the model workflow, the effect of PCA could not be adequately measured. 

An _appropriate_ approach would be: 

```{r workflow-good, echo = FALSE, out.width = '80%', warning = FALSE}
if (knitr:::is_html_output()) {
  file.copy("premade/proper-workflow.svg", "_book/premade/proper-workflow.svg")
  knitr::include_graphics("premade/proper-workflow.svg")
} else {
  file.copy("premade/proper-workflow.pdf", "_book/premade/proper-workflow.pdf")
  knitr::include_graphics("premade/proper-workflow.pdf")
}
```

In this way, the PCA pre-processing is considered part of the modeling process. 

## Workflow basics

The `workflows` package allows the user to bind modeling objects together. Let's start again with the Ames data with a simple linear model:

```{r workflows-simple}
library(tidymodels)  # Includes the workflows package

lm_model <- 
  linear_reg() %>% 
  set_engine("lm")
```

A workflow always requires a `parsnip` model object: 

```{r workflows-model-only}
lm_wflow <- 
  workflow() %>% 
  add_model(lm_model)
lm_wflow
```

If our model were very simple, a standard R formula can be attached: 


```{r workflows-form}
lm_wflow <- 
  lm_wflow %>% 
  add_formula(log10(Sale_Price) ~ Longitude + Latitude)
lm_wflow
```

Workflows have a simple `fit()` method that can be used to create the model

```{r workflows-form-fit}
lm_wflow_fit <- fit(lm_wflow, ames_train)
lm_wflow_fit
```

as well as a `predict()` method:


```{r workflows-form-pred}
predict(lm_wflow_fit, ames_test %>% slice(1:3))
```

Both the model and formula can be removed or updated 

```{r workflows-form-update}
lm_wflow_fit %>% 
  update_formula(log10(Sale_Price) ~ Longitude)
```

Note that, in this new object, the output shows that the previous fitted model was removed since the new formula was inconsistent with the previous model fit. 

### The role of model formulas in base R 

**more here about the differences in the formula method and how `model.matrix()` does things**

**describe blueprints and show when to use them here?**

## Workflows and recipes

Instead of using model formulas, recipe objects can also be used. From the previous chapter, the following recipe was derived: 

```{r workflows-ames-recipe}
ames_rec <- 
  recipe(Sale_Price ~ Neighborhood + Gr_Liv_Area + Year_Built + Bldg_Type + 
           Latitude + Longitude, data = ames_train) %>%
  step_log(Gr_Liv_Area, base = 10) %>% 
  step_other(Neighborhood, threshold = 0.01) %>% 
  step_dummy(all_nominal()) %>% 
  step_interact(~ Gr_Liv_Area:starts_with("Bldg_Type_")) %>% 
  step_ns(Latitude, Longitude, deg_free = 20)
```

This can be attached to the workflow...

```{r workflows-fail, error = TRUE}
lm_wflow %>% 
  add_recipe(ames_rec)
```

although you can only have one pre-processing method at a time. 

```{r workflows-add-recipe}
lm_wflow <- 
  lm_wflow %>% 
  remove_formula() %>% 
  add_recipe(ames_rec)
lm_wflow
```

From Section \@ref(recipes-manual), the `prep()`, `bake()`, and `juice()` functions were described when preparing the data for a modeling function. If this seemed onerous, the `fit()` method for workflow objects automates this process: 

```{r workflows-recipe-fit}
# Does `prep()`, `juice()`, and `fit()` in one step:
lm_wflow_fit <- fit(lm_wflow, ames_train)

# Does `bake()` and `predict()` automatically:
predict(lm_wflow_fit, ames_test %>% slice(1:3))
```

In case the naked model object or recipe are needed, there are `pull_*` functions that can retrieve them: 

```{r workflows-pull}
# Get the recipe and run `tidy()` method: 
lm_wflow_fit %>% 
  pull_workflow_prepped_recipe() %>% 
  tidy()

# To tidy the model fit: 
lm_wflow_fit %>% 
  # This returns the parsnip object:
  pull_workflow_fit() %>% 
  # As before, `pluck()` is used to get the `fit` element:
  pluck("fit") %>% 
  # Now tidy the linear model object:
  tidy() %>% 
  slice(1:5)
```

**changing models and/or recipes**

**passing another formula to the model**


## Future plans

Currently, a workflow can accept two types of pre-processors: a model formula or a recipe. While recipes are very flexible, they do not encompass everything that a user might want to do to the data prior to modeling. For example, a _supervised feature filter_ might be of interest. This would screen predictors against the outcome using the training set and use the results to remove the least relevant predictors. In the future, a specification for this type of pre-model operation will be passed to a workflow to include it in the modeling process. This is a critical step that can have a profound effect on model performance. As discussed in the next chapter, a common pitfall in modeling is to exclude this step from the model evaluation process. 

There are also operations that might occur _after_ the model is fit. An example of such a _post-processor_ would be cutoff selection for two-class problems. Previously in this chapter, the idea of modifying the cutoff for a two-class problem was discussed. In the future, workflows will be able to attach a custom cutoff that is applied to probabilities after the model fit. Other approaches, such as probability calibration, could also be added as post-processors. 
  
